{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e3b8525-264b-4cca-9264-74c97ac2f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from threading import Thread # you can use easier threading packages\n",
    "import sqlite3 as sqlite3\n",
    "import csv\n",
    "from csv import writer\n",
    "import shutil\n",
    "# ml\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# visual\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# notebook\n",
    "from IPython.display import display\n",
    "import os\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bca969d-a410-418c-8f31-fdc466196815",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "for i in range(1,21):   \n",
    "    firstname = ['John', 'Dana', 'Scott', 'Marc', 'Steven', 'Michael', 'Albert', 'Johanna']\n",
    "    city = ['NewYork', 'Haifa', 'Munchen', 'London', 'PaloAlto',  'TelAviv', 'Kiel', 'Hamburg']\n",
    "    secondname = ['Kelly','Brenda','Brendon','Steve','Jonah','Amy','Alex','Jerry']\n",
    "    \n",
    "    my_firstname= []\n",
    "    my_city = []\n",
    "    my_secondname = []\n",
    "    \n",
    "    for x in range(10):\n",
    "        my_firstname.append(random.choice(firstname))\n",
    "        my_city.append(random.choice(city))\n",
    "        my_secondname.append(random.choice(secondname))\n",
    "    \n",
    "    myCSV = pd.DataFrame(list(zip(my_firstname,my_secondname,my_city)), columns =['firstname','secondname','city'])\n",
    "    myCSV.to_csv('myCSV%s.csv' %i,encoding='utf-8',index = False)\n",
    "    input_data.append('myCSV%s.csv' %i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e22b6d52-ef9f-4fb8-8ef1-dc2a4554403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createfolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print (\"Error creating directory\" + directory)\n",
    "createfolder('./mapreducetemp/')\n",
    "\n",
    "temp_results = pd.DataFrame(columns =['key','value'])\n",
    "temp_results.to_csv('temp_results.csv',encoding='utf-8',index = False)\n",
    "csvs_map = []\n",
    "csvs_reduce = []\n",
    "conn = sqlite3.connect('temp_results')\n",
    "c = conn.cursor()\n",
    "c.execute('CREATE TABLE IF NOT EXISTS temp_results (key text, value text)')\n",
    "conn.commit()\n",
    "createfolder('./mapreducetemp/')\n",
    "createfolder('./mapreducefinal/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "377c5b26-e382-4b82-ac61-c48b0e93ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(filename,chunk=16000):\n",
    "    size=os.path.getsize(filename)\n",
    "    part = int(size/chunk)\n",
    "    size_left=size           \n",
    "    fp = open(filename, 'rb')\n",
    "    chunk_rows = []\n",
    "    while (size_left>0):\n",
    "        if (size_left<chunk):\n",
    "            current_chunk = size_left\n",
    "        else : \n",
    "            current_chunk = chunk\n",
    "        fp.seek(size-size_left+1, 0)\n",
    "        d2=fp.read(current_chunk).decode(\"utf-8\")\n",
    "        rows=d2.count(\"\\n\")\n",
    "        size_left-=current_chunk\n",
    "        chunk_rows.append(rows)\n",
    "    return(chunk_rows)\n",
    "\n",
    "\n",
    "def map_function(filename,x):\n",
    "    print(f'Starting task: {x}...')\n",
    "    data = pd.read_csv(filename)\n",
    "    f= open('mapreducetemp/part-tmp-%s.csv'%x, 'w', encoding='UTF8',newline='') \n",
    "    csvs_map.append('mapreducetemp/part-tmp-%s.csv'%x)\n",
    "    writer = csv.writer(f)\n",
    "    header=[\"key\",\"value\"]\n",
    "    writer.writerow(header)\n",
    "    keyval=['0','0']\n",
    "    for j in range (data.shape[0]):\n",
    "        for line in (data.iloc[j,:]):\n",
    "            words= line.split()\n",
    "            for word in words:\n",
    "                keyval[0]=word\n",
    "                keyval[1]=filename\n",
    "                writer.writerow(keyval)\n",
    "    print(f'Finished task: {x}...')\n",
    "    j+=1  \n",
    "    return f.name\n",
    "\n",
    "def batch(input_data,threshold=64000):\n",
    "    size = 0\n",
    "    x = 1\n",
    "    batches = []\n",
    "    all_data = pd.DataFrame()\n",
    "    data = pd.DataFrame()\n",
    "    for filename in input_data:\n",
    "        if os.path.getsize(filename) > threshold:\n",
    "            s = os.path.getsize(filename)\n",
    "            all_chunks = chunks(filename,threshold)\n",
    "            first = 0\n",
    "            for chunk in all_chunks:      \n",
    "                data = pd.read_csv(filename).iloc[first:chunk]\n",
    "                f=open('mapreducetemp/batch-tmp-%s.csv'%x, 'w', encoding='UTF8',newline='')\n",
    "                batches.append('mapreducetemp/batch-tmp-%s.csv'%x)\n",
    "                data.to_csv(f,header=False,index=False)\n",
    "                first+=chunk\n",
    "                x+=1\n",
    "        elif size + os.path.getsize(filename) <= threshold:\n",
    "            all_data=all_data.append(data)\n",
    "            data = pd.read_csv(filename)\n",
    "            all_data=all_data.append(data.iloc[1:])\n",
    "            size += os.path.getsize(filename)\n",
    "        elif size + os.path.getsize(filename) > threshold:\n",
    "            f= open('mapreducetemp/batch-tmp-%s.csv'%x, 'w', encoding='UTF8',newline='') \n",
    "            all_data.to_csv(f,header=False,index=False)\n",
    "            batches.append('mapreducetemp/batch-tmp-%s.csv'%x)\n",
    "            x+=1\n",
    "            data = pd.read_csv(filename)\n",
    "            f= open('mapreducetemp/batch-tmp-%s.csv'%x, 'w', encoding='UTF8',newline='')       \n",
    "            size = os.path.getsize(filename)\n",
    "    if batches == []:\n",
    "        f= open('mapreducetemp/batch-tmp-%s.csv'%x, 'w', encoding='UTF8',newline='')\n",
    "        all_data.to_csv(f,header=False,index=False)\n",
    "        batches.append('mapreducetemp/batch-tmp-%s.csv'%x)\n",
    "    print(batches)\n",
    "    return batches\n",
    "\n",
    "\n",
    "def thread_map_func(input_data ,Function=map_function,threshold=64000):\n",
    "    # create threads\n",
    "    threads = []\n",
    "    x = 1\n",
    "    batches = batch(input_data,threshold=threshold)\n",
    "    for filename in batches:\n",
    "        thread = Thread(target=Function, args=(filename,x))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "        x+=1\n",
    "\n",
    "    # wait for the threads to complete\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    print(\"finished mapping\")\n",
    "    \n",
    "#load all csv's to the temp table\n",
    "# def Temptable(filename):\n",
    "def load_data(csvs_map):\n",
    "    conn = sqlite3.connect('temp_results')\n",
    "    c = conn.cursor()\n",
    "    for file in csvs_map:\n",
    "            df = pd.read_csv(file)\n",
    "            df.to_sql('temp_results', conn, if_exists='append', index = False)\n",
    "    c.execute('''SELECT  key,group_concat(value) \n",
    "         FROM temp_results\n",
    "         GROUP BY 1\n",
    "         ORDER BY 2 \n",
    "                 ''')\n",
    "    df1 = pd.DataFrame(c.fetchall(),columns=['key','value'])    \n",
    "    return df1\n",
    "\n",
    "def reduce_function(key,value,x):\n",
    "    print(f'Starting task: {x}...')\n",
    "    f= open('mapreducefinal/part-%s-final.csv'%x, 'w', encoding='UTF8',newline='') \n",
    "    csvs_reduce.append('mapreducefinal/part-%s-final.csv'%x)\n",
    "    writer = csv.writer(f)\n",
    "    header=[\"key\",\"value\"]\n",
    "    writer.writerow(header)\n",
    "    keyval=[key,len(value.split(','))]\n",
    "    writer.writerow(keyval)\n",
    "    print(f'Finished task: {x}...') \n",
    "    return f.name\n",
    "\n",
    "def thread_reduce_func(csvs_map ,Function=reduce_function):\n",
    "    df = load_data(csvs_map)\n",
    "    key,value = df['key'],df['value']\n",
    "    # create threads\n",
    "    threads = []\n",
    "    x = 1\n",
    "    for i in range(df.shape[0]):\n",
    "        thread = Thread(target=Function, args=(key[i],value[i],x))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "        x+=1\n",
    "\n",
    "    # wait for the threads to complete\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    print('MapReduce Completed')\n",
    "\n",
    "class MapReduceEngine():\n",
    "    def execute(self,input_data, map_function, reduce_function,threshold):\n",
    "        thread_map_func(input_data,map_function,threshold)\n",
    "        thread_reduce_func(csvs_map ,Function = reduce_function) \n",
    "# p1 = MapReduceEngine()\n",
    "# p1.execute(input_data, map_function, reduce_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf39acc3-e561-49ad-8d35-4899f1be2ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mapreducetemp/batch-tmp-1.csv', 'mapreducetemp/batch-tmp-2.csv', 'mapreducetemp/batch-tmp-3.csv', 'mapreducetemp/batch-tmp-4.csv', 'mapreducetemp/batch-tmp-5.csv', 'mapreducetemp/batch-tmp-6.csv', 'mapreducetemp/batch-tmp-7.csv', 'mapreducetemp/batch-tmp-8.csv', 'mapreducetemp/batch-tmp-9.csv', 'mapreducetemp/batch-tmp-10.csv', 'mapreducetemp/batch-tmp-11.csv', 'mapreducetemp/batch-tmp-12.csv', 'mapreducetemp/batch-tmp-13.csv', 'mapreducetemp/batch-tmp-14.csv', 'mapreducetemp/batch-tmp-15.csv', 'mapreducetemp/batch-tmp-16.csv', 'mapreducetemp/batch-tmp-17.csv', 'mapreducetemp/batch-tmp-18.csv', 'mapreducetemp/batch-tmp-19.csv']\n",
      "Starting task: 1...\n",
      "Starting task: 2...\n",
      "Starting task: 3...\n",
      "Starting task: 4...\n",
      "Starting task: 5...\n",
      "Starting task: 6...\n",
      "Starting task: 7...Finished task: 1...Starting task: 8...\n",
      "Finished task: 2...\n",
      "\n",
      "Finished task: 3...Starting task: 9...\n",
      "Finished task: 4...\n",
      "Finished task: 5...Starting task: 10...\n",
      "Finished task: 7...\n",
      "\n",
      "\n",
      "Starting task: 11...\n",
      "Finished task: 8...\n",
      "\n",
      "Starting task: 12...Finished task: 6...Starting task: 13...\n",
      "\n",
      "Starting task: 14...\n",
      "\n",
      "Starting task: 15...\n",
      "Starting task: 16...\n",
      "Starting task: 17...\n",
      "Starting task: 18...\n",
      "Starting task: 19...\n",
      "Finished task: 12...Finished task: 15...Finished task: 16...\n",
      "Finished task: 14...\n",
      "\n",
      "Finished task: 11...\n",
      "Finished task: 19...\n",
      "Finished task: 17...\n",
      "Finished task: 13...Finished task: 10...\n",
      "\n",
      "\n",
      "Finished task: 9...Finished task: 18...\n",
      "\n",
      "finished mapping\n",
      "Starting task: 1...Starting task: 2...\n",
      "Starting task: 3...\n",
      "\n",
      "Finished task: 1...\n",
      "Finished task: 3...\n",
      "Starting task: 4...\n",
      "Starting task: 5...Finished task: 2...Starting task: 6...\n",
      "\n",
      "Finished task: 4...\n",
      "Starting task: 7...\n",
      "\n",
      "Finished task: 6...\n",
      "Finished task: 5...Starting task: 8...Finished task: 7...\n",
      "Starting task: 9...\n",
      "\n",
      "Starting task: 10...\n",
      "\n",
      "Starting task: 11...Finished task: 8...Starting task: 12...\n",
      "\n",
      "\n",
      "Starting task: 13...Finished task: 9...\n",
      "Finished task: 10...\n",
      "\n",
      "Finished task: 12...Starting task: 14...Finished task: 11...Starting task: 15...\n",
      "\n",
      "\n",
      "\n",
      "Starting task: 16...\n",
      "Finished task: 13...Finished task: 15...Finished task: 14...\n",
      "\n",
      "Finished task: 16...\n",
      "\n",
      "MapReduce Completed\n"
     ]
    }
   ],
   "source": [
    "p1 = MapReduceEngine()\n",
    "p1.execute(input_data, map_function, reduce_function,threshold=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
